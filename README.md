# LLMcooker
If you don't know what you want to eat. Upload an image for all foods (vegetables, meats, fruits) you have. The LLM will find you a way out. This application includes an interface and a local/offline LLM. 

# How to apply
1. load a local LLM model. My other repository[Load-local-LLMs](https://github.com/zsdnb0901/Load-local-LLMs) shows the details (Qwen2.5vl:7b is used in this code)
2. install requirements.txt then run main.py
3. upload an image of all foods
4. click "analyze"
5. click "recommand"
6. you will see some dishes recommandation and basic steps

# Layout
Here is a brief layout of the interface. 

<img width="1000" height="631" alt="image" src="https://github.com/user-attachments/assets/7d6eda16-a640-4973-bb5f-869685c3ef6b" />


# My specs
Processor: AMD Ryzen 7 5700X 8-Core Processor, 3800Mhz, 16GB RAM

GPU: NVIDIA GeForce RTX 3060 Ti

The local LLM this code is qwen2.5. Downloaded from Ollama. 
